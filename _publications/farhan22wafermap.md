---
layout: publication
sitemap: false
title: "High Accuracy Swin Transformers for Image-based Wafer Map Defect Detection"
authors: Thahmidul I. Nafi, Erfanul Haque, <b>Faisal Farhan</b>, Asif Rahman.
pdf: farhan22wafermap
image: farhan22wafermap.png
display: International Journal of Engineering and Manufacturing (IJEM)
year: 2022
doi: https://doi.org/10.5815/ijem.2022.05.02
abstract: "A wafer map depicts the location of each die on the wafer and indicates whether it is a Product, Secondary Silicon, or Reject. Detecting defects in Wafer Maps is crucial in order to ensure the integrity of the chips processed in the wafer, as any defect can cause anomalies thus decreasing the overall yield. With the current advances in anomaly detection using various Computer Vision Techniques, Transformer Architecture based Vision models are a prime candidate for identifying wafer defects. In this paper, the performance of Four such Transformer based models – BEiT (BERT Pre-Training of Image Transformers), FNet (Fourier Network), ViT (Vision Transformer) and Swin Transformer (Shifted Window based Transformer) in wafer map defect classification are discussed. Each of these models were individually trained, tested and evaluated with the “MixedWM38” dataset obtained from the online platform, Kaggle. During evaluation, it has been observed that the overall accuracy of the Swin Transformer Network algorithm is the highest, at 97.47%, followed closely by Vision Transformer at 96.77%. The average Recall of Swin Transformer is also 97.54%, which indicates an extremely low encounter of false negatives (24600 ppm) in contrast to true positives, making it less likely to expose defective products in the market."
---