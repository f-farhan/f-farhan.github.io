- title: "Identifying lane changes automatically using the GPS sensors of portable devices"
  authors: Driessen, T., Prasad, L., Bazilinskyy, P., De Winter, J. C. F.
  url: driessen2022identifying
  image: driessen2022identifying.jpg
  display: Proceedings of International Conference on Applied Human Factors and Ergonomics (AHFE). New York, USA
  year: 2022
  code: https://github.com/tomdries/gps-lane-changes
  suppmat: https://doi.org/10.4121/19170302
  abstract: "Mobile applications that provide GPS-based route navigation advice or driver diagnostics are gaining popularity. However, these applications currently do not have knowledge of whether the driver is performing a lane change. Having such information may prove valuable to individual drivers (e.g., to provide more specific navigation instructions) or road authorities (e.g., knowledge of lane change hotspots may inform road design). The present study aimed to assess the accuracy of lane change recognition algorithms that rely solely on mobile GPS sensor input. Three trips on Dutch highways, totaling 158 km of driving, were performed while carrying two smartphones (Huawei P20, Samsung Galaxy S9), a GPS-equipped GoPro Max, and a USB GPS receiver (GlobalSat BU343-s4). The timestamps of all 215 lane changes were manually extracted from the forward-facing GoPro camera footage, and used as ground truth. After connecting the GPS trajectories to the road using Mapbox Map Matching API (2022), lane changes were identified based on the exceedance of a lateral translation threshold in set time windows. Different thresholds and window sizes were tested for their ability to discriminate between a pool of lane change segments and an equally-sized pool of no-lane-change segments. The overall accuracy of the lane-change classification was found to be 90%. The method appears promising for highway engineering and traffic behavior research that use floating car data, but there may be limited applicability to real-time advisory systems due to the occasional occurrence of false positives."

- title: "Stopping by looking: A driver-pedestrian interaction study in a coupled simulator using head-mounted displays with eye-tracking"
  authors: Mok, C. S., Bazilinskyy, P., De Winter, J. C. F.
  url: mok2022stopping
  image: mok2022stopping.jpg
  display: Applied Ergonomics, 105, 103825
  suppmat: https://www.sciencedirect.com/science/article/pii/S000368702200148X#appsec1
  year: 2022
  doi: 10.1016/j.apergo.2022.103825
  abstract: "Automated vehicles (AVs) can perform low-level control tasks but are not always capable of proper decision-making. This paper presents a concept of eye-based maneuver control for AV-pedestrian interaction. Previously, it was unknown whether the AV should conduct a stopping maneuver when the driver looks at the pedestrian or looks away from the pedestrian. A two-agent experiment was conducted using two head-mounted displays with integrated eye-tracking. Seventeen pairs of participants (pedestrian and driver) each interacted in a road crossing scenario. The pedestrians' task was to hold a button when they felt safe to cross the road, and the drivers' task was to direct their gaze according to instructions. Participants completed three 16-trial blocks: (1) Baseline, in which the AV was pre-programmed to yield or not yield, (2) Look to Yield (LTY), in which the AV yielded when the driver looked at the pedestrian, and (3) Look Away to Yield (LATY), in which the AV yielded when the driver did not look at the pedestrian. The driver's eye movements in the LTY and LATY conditions were visualized using a virtual light beam. Crossing performance was assessed based on whether the pedestrian held the button when the AV yielded and released the button when the AV did not yield. Furthermore, the pedestrians' and drivers' acceptance of the mappings was measured through a questionnaire. The results showed that the LTY and LATY mappings yielded better crossing performance than Baseline. Furthermore, the LTY condition was best accepted by drivers and pedestrians. Eye-tracking analyses indicated that the LTY and LATY mappings attracted the pedestrian's attention, while pedestrians still distributed their attention between the AV and a second vehicle approaching from the other direction. In conclusion, LTY control may be a promising means of AV control at intersections before full automation is technologically feasible."

- title: "Get out of the way! Examining eHMIs in critical driver-pedestrian encounters in a coupled simulator"
  authors: Bazilinskyy, P., Kooijman, L., Dodou, D., Mallant, K. P. T., Roosens, V. E. R., Middelweerd, M. D. L. M., Overbeek, L. D., De Winter, J. C. F.
  url: bazilinskyy2022get
  image: bazilinskyy2022get.jpg
  display: Proceedings of International ACM Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutoUI)
  year: 2022
  doi: 
  code: https://github.com/bazilinskyy/coupled-sim-evasive
  suppmat: https://doi.org/10.4121/20224281
  abstract: "Past research suggests that displays on the exterior of the car, known as eHMIs, can be effective in helping pedestrians to make safe crossing decisions. This study examines a new application of eHMIs, namely the provision of directional information in scenarios where the pedestrian is almost hit by a car. In an experiment using a head-mounted display and a motion suit, participants had to cross the road while a car driven by another participant approached them. The results showed that the directional eHMI caused pedestrians to step back compared to no eHMI. The eHMI increased the pedestrians’ self-reported understanding of the car’s intention, although some pedestrians did not notice the eHMI. In conclusion, there may be potential for supporting pedestrians in situations where they need support the most, namely critical encounters. Future research may consider coupling a directional eHMI to autonomous emergency steering."

- title: "High Accuracy Swin Transformers for Image-based Wafer Map Defect Detection"
  authors: Thahmidul I. Nafi, Erfanul Haque, <b>Faisal Farhan</b>, Asif Rahman.
  url: farhan22wafermap
  image: farhan22wafermap.png
  display: International Journal of Engineering and Manufacturing (IJEM)
  year: 2022
  doi: https://doi.org/10.5815/ijem.2022.05.02
  abstract: "A wafer map depicts the location of each die on the wafer and indicates whether it is a Product, Secondary Silicon, or Reject. Detecting defects in Wafer Maps is crucial in order to ensure the integrity of the chips processed in the wafer, as any defect can cause anomalies thus decreasing the overall yield. With the current advances in anomaly detection using various Computer Vision Techniques, Transformer Architecture based Vision models are a prime candidate for identifying wafer defects. In this paper, the performance of Four such Transformer based models – BEiT (BERT Pre-Training of Image Transformers), FNet (Fourier Network), ViT (Vision Transformer) and Swin Transformer (Shifted Window based Transformer) in wafer map defect classification are discussed. Each of these models were individually trained, tested and evaluated with the “MixedWM38” dataset obtained from the online platform, Kaggle. During evaluation, it has been observed that the overall accuracy of the Swin Transformer Network algorithm is the highest, at 97.47%, followed closely by Vision Transformer at 96.77%. The average Recall of Swin Transformer is also 97.54%, which indicates an extremely low encounter of false negatives (24600 ppm) in contrast to true positives, making it less likely to expose defective products in the market."

#- title: "Predicting perceived risk of traffic scenes using computer vision"
#  authors: De Winter, J. C. F., Hoogmoed, J., Stapel, J., Dodou, D., Bazilinskyy, P.
#  url: dewinter2023predicting
#  image: dewinter2023predicting.jpg
#  display: "Transportation Research Part F: Traffic Psychology and Behaviour, 84, 194-210"
#  year: 2023
#  doi: 10.1016/j.trf.2023.01.014
#  suppmat: https://doi.org/10.4121/21952685
#  code: https://github.com/bazilinskyy/risk-dash-crowdsourcing
#  abstract: "Perceived risk, or subjective risk, is an important concept in the field of traffic psychology and automated driving. In this paper, we investigate whether perceived risk in images of traffic scenes can be predicted from computer vision features that may also be used by automated vehicles (AVs). We conducted an international crowdsourcing study with 1378 participants, who rated the perceived risk of 100 randomly selected dashcam images on German roads. The population-level perceived risk was found to be statistically reliable, with a split-half reliability of 0.98. We used linear regression analysis to predict (r = 0.62) perceived risk from two features obtained with the YOLOv4 computer vision algorithm: the number of people in the scene and the mean size of the bounding boxes surrounding other road users. When the ego-vehicle’s speed was added as a predictor variable, the prediction strength increased to r = 0.75. Interestingly, the sign of the speed prediction was negative, indicating that a higher vehicle speed was associated with a lower perceived risk. This finding aligns with the principle of self-explaining roads. Our results suggest that computer-vision features and vehicle speed contribute to an accurate prediction of population subjective risk, outperforming the ratings provided by individual participants (mean r = 0.41). These findings may have implications for AV development and the modeling of psychological constructs in traffic psychology."

# - title: "Intent communication in nature: An overview of biological paradigms and their applicability to automated vehicle"
#   authors: Oudshoorn, M. P. J., De Winter, J. C. F., Bazilinskyy, P., Dodou, D.
#   url: oudshoorn2021intent
#   image: oudshoorn2021intent.jpg
#   display: Manuscript in preparation
#   year:
#   abstract: "With the advent of automated vehicles (AVs), several means of visual communication that are currently used in interactions between a human driver and pedestrians (e.g., eye contact, hand gestures) may no longer be available. External human-machine interfaces (eHMIs) can serve to communicate intent from the AV to pedestrians. There are numerous methods of intent-communication methods in nature which, due to their long evolution, might provide inspiration for the design of effective and intuitive eHMIs. This paper reviews visual intent-communication methods in nature and investigates their applicability for eHMIs. We found that posture, gesture, facial expression, colouration, and bioluminescence are common intent-communication methods used in nature for a variety of functions, including agonistic interactions, courtship rituals, alarm calls, and food acquisition. Gestures and colouration appear to be used for all function types, and posture and facial expression are more often employed in agonistic interactions (i.e., social behaviours related to fighting). Signals were often dynamic, which increases their detectability. The simultaneous use of multiple channels was often encountered. Inspired by the identified communication methods in nature, we provided suggestions about how these methods can be translated to eHMI design concepts, including changing the size of the vehicle, using foldable structures, and applying conspicuous colouration to the body of the AV."
# UNDER REVIEW

- title: "Exterior sounds for electric and automated vehicles: Loud is effective"
  authors: Bazilinskyy, P., Merino-Martınez, R., Vieirac, E. O., Dodou, D., De Winter, J. C. F.
  url: bazilinskyy2023exterior
  image: bazilinskyy2023exterior.jpg
  display: <b>Manuscript submitted for publication</b>
  year:
  abstract: "Exterior vehicle sounds have been introduced in electric vehicles and as external human-machine interfaces for automated vehicles. While previous research has studied the effect of exterior vehicle sounds on detectability and acceptance, the present study takes on a different approach by examining the efficacy of such vehicle sounds in deterring people from crossing the road. An online study was conducted in which 226 participants were presented with different types of synthetic sounds, including sounds of a combustion engine, pure tones, combined tones, and beeps. A vehicle moving in a straight trajectory at a constant velocity of 30 km/h was used, and no visual information was provided. Participants in the role of pedestrians were asked to hold down a key when they felt safe to cross. After each trial, they assessed whether the vehicle sound was easy to notice, whether it gave enough information to realize that a vehicle was approaching, and whether the sound was annoying. The results showed that sounds of higher modeled perceived loudness, such as continuous tones with high frequency, were the most effective in deterring participants from crossing the road. The tested intermittent beeps proved to be relatively ineffective, presumably because no valuable information could be derived during the inter-pulse intervals. Tire noise proved to be relatively effective in deterring participants from crossing, and was found to be the least annoying. These results may prove insightful for the improvement of synthetic exterior vehicle sounds."



# - title: ""
#   authors:
#     F.Farhan
#   url: f-farhan.github.io
#   image: dummy.jpg
#   display:
#   year:
#   doi:
#   suppmat:
#   abstract: ""